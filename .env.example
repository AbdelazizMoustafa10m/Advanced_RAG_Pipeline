# Advanced RAG Pipeline - Environment Variables Example
# Copy this file to .env and fill in your values

GROQ_API_KEY=your_groq_api_key_here

OPENAI_API_KEY=your_openai_api_key_here

GEIMINI_API_KEY=your_geimini_api_key_here


# ===== LLM Configuration =====

# Metadata LLM (for document/code enrichment)
METADATA_LLM_PROVIDER=groq
METADATA_LLM_MODEL=llama-3.1-8b-instant
METADATA_LLM_API_KEY_ENV_VAR=GROQ_API_KEY


# Query LLM (for RAG queries)
QUERY_LLM_PROVIDER=groq
QUERY_LLM_MODEL=llama-3.1-70b-versatile
QUERY_LLM_API_KEY_ENV_VAR=GROQ_API_KEY

# Coding LLM (for code-specific tasks)
CODING_LLM_PROVIDER=groq
CODING_LLM_MODEL=llama-3.1-70b-instant
CODING_LLM_API_KEY_ENV_VAR=GROQ_API_KEY

# ===== Embedder Configuration =====

# HuggingFace Embeddings (default)
EMBEDDER_PROVIDER=huggingface
EMBEDDER_MODEL=BAAI/bge-small-en-v1.5
EMBEDDER_BATCH_SIZE=10

# OpenAI Embeddings
# EMBEDDER_PROVIDER=openai
# EMBEDDER_MODEL=text-embedding-3-small
# EMBEDDER_API_KEY_ENV_VAR=OPENAI_API_KEY
# OPENAI_API_KEY=your_openai_api_key_here

# Cohere Embeddings
# EMBEDDER_PROVIDER=cohere
# EMBEDDER_MODEL=embed-english-v3.0
# EMBEDDER_API_KEY_ENV_VAR=COHERE_API_KEY
# COHERE_API_KEY=your_cohere_api_key_here

# Vertex AI Embeddings
# EMBEDDER_PROVIDER=vertex
# EMBEDDER_MODEL=textembedding-gecko@003
# EMBEDDER_API_KEY_ENV_VAR=VERTEX_API_KEY
# VERTEX_API_KEY=your_vertex_api_key_here

# AWS Bedrock Embeddings
# EMBEDDER_PROVIDER=bedrock
# EMBEDDER_MODEL=amazon.titan-embed-text-v1
# AWS_ACCESS_KEY_ID=your_aws_access_key_id
# AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
# AWS_REGION=us-east-1

# Ollama Embeddings (local)
# EMBEDDER_PROVIDER=ollama
# EMBEDDER_MODEL=nomic-embed-text
# EMBEDDER_API_BASE=http://localhost:11434
# EMBEDDER_BATCH_SIZE=4

# ===== Vector Store Configuration =====

# ChromaDB settings
VECTOR_DB_PATH=./vector_db
COLLECTION_NAME=unified_knowledge

# ===== Parallel Processing =====
MAX_WORKERS=4

# ===== Document Registry =====
DOCUMENT_REGISTRY_DB_PATH=./doc_reg_db/document_registry.db
